{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "363ff815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.minmax_normalizer import MinMaxNormalization\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ddb264c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4848, 2, 32, 32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_data1 = pd.read_csv('../Datasets/TaxiBJ_main/TAXIBJ2013.grid')\n",
    "flow_data_groups = flow_data.groupby('time')\n",
    "flow_data_groups = list(flow_data_groups)[1:]\n",
    "size = len(flow_data_groups)\n",
    "\n",
    "flow_data = np.empty([size, 2, 32, 32])\n",
    "for i in range(size):\n",
    "    data = flow_data_groups[i][1]\n",
    "    data_inflow = data.pivot_table(values='inflow', index='row_id', columns='column_id').to_numpy()\n",
    "    data_outflow = data.pivot_table(values='outflow', index='row_id', columns='column_id').to_numpy()\n",
    "    entire_data[i, 0] = data_inflow\n",
    "    entire_data[i, 1] = data_outflow\n",
    "    \n",
    "flow_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318bd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected flow_data shape: (N, 2, 32, 32)\n",
    "def get_taxibj_data(flow_data,n_closeness,n_period,n_trend,tt_split,g_closeness=2,g_period=48,g_trend=48*7):\n",
    "    data_len, feature, map_height, map_width = flow_data.shape\n",
    "    assert ((n_closeness,n_period,n_trend) < (7,4,3))\n",
    "    start_idx = g_trend*n_trend\n",
    "    total_samples = data_len-start_idx\n",
    "    n_train = int(total_samples*tt_split)\n",
    "    n_test = total_samples-n_train\n",
    "    mmn = MinMaxNormalization()\n",
    "    flow_data = mmn.fit_transform(flow_data)\n",
    "    \n",
    "    tstamp_train = np.zeros(n_train)\n",
    "    y_train = np.zeros((n_train,2,map_height,map_width))\n",
    "    x_closeness_train = np.zeros((n_train,n_closeness,2,map_height,map_width))    \n",
    "    x_period_train = np.zeros((n_train,n_period,2,map_height,map_width))\n",
    "    x_trend_train = np.zeros((n_train,n_trend,2,map_height,map_width))\n",
    "    k = 0\n",
    "    for i in range(start_idx,start_idx+n_train):    \n",
    "        tstamp_train[k] = i\n",
    "        y_train[k,:,:,:] = flow_data[i,:,:,:]\n",
    "        l = 0\n",
    "        for j in range(i-g_trend, i-g_trend*(n_trend+1), -g_trend):\n",
    "            x_trend_train[k,l,:,:,:] = flow_data[j,:,:,:]\n",
    "            l += 1        \n",
    "        l = 0\n",
    "        for j in range(i-g_period, i-g_period*(n_period+1), -g_period):            \n",
    "            x_period_train[k,l,:,:,:] = flow_data[j,:,:,:]\n",
    "            l += 1\n",
    "        l = 0\n",
    "        for j in range(i-g_closeness, i-g_closeness*(n_closeness+1), -g_closeness):            \n",
    "            x_closeness_train[k,l,:,:,:] = flow_data[j,:,:,:]\n",
    "            l += 1\n",
    "        k += 1    \n",
    "    x_closeness_train = x_closeness_train.reshape(n_train,-1,map_height,map_width)\n",
    "    x_period_train = x_period_train.reshape(n_train,-1,map_height,map_width)\n",
    "    x_trend_train = x_trend_train.reshape(n_train,-1,map_height,map_width)\n",
    "    \n",
    "    start_idx += n_train\n",
    "    tstamp_test = np.zeros(n_test)\n",
    "    y_test = np.zeros((n_test,2,map_height,map_width))\n",
    "    x_closeness_test = np.zeros((n_test,n_closeness,2,map_height,map_width))    \n",
    "    x_period_test = np.zeros((n_test,n_period,2,map_height,map_width))\n",
    "    x_trend_test = np.zeros((n_test,n_trend,2,map_height,map_width))\n",
    "    k = 0\n",
    "    for i in range(start_idx,start_idx+n_test):\n",
    "        tstamp_test[k] = i\n",
    "        y_test[k,:,:,:] = flow_data[i,:,:,:]\n",
    "        l = 0\n",
    "        for j in range(i-g_trend, i-g_trend*(n_trend+1), -g_trend):\n",
    "            x_trend_test[k,l,:,:,:] = flow_data[j,:,:,:]\n",
    "            l += 1        \n",
    "        l = 0\n",
    "        for j in range(i-g_period, i-g_period*(n_period+1), -g_period):            \n",
    "            x_period_test[k,l,:,:,:] = flow_data[j,:,:,:]\n",
    "            l += 1\n",
    "        l = 0\n",
    "        for j in range(i-g_closeness, i-g_closeness*(n_closeness+1), -g_closeness):            \n",
    "            x_closeness_test[k,l,:,:,:] = flow_data[j,:,:,:]\n",
    "            l += 1\n",
    "        k += 1\n",
    "    x_closeness_test = x_closeness_test.reshape(n_test,-1,map_height,map_width)\n",
    "    x_period_test = x_period_test.reshape(n_test,-1,map_height,map_width)\n",
    "    x_trend_test = x_trend_test.reshape(n_test,-1,map_height,map_width)\n",
    "    \n",
    "    return tstamp_train, x_closeness_train, x_period_train, x_trend_train, y_train, x_closeness_test, x_period_test, x_trend_test, y_test\n",
    "    \n",
    "# get_bikenyc_data(np.load('./Datasets/BikeNYC/flow_data.npy'),4,1,1,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9585ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0 max: 737.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class BikeNYCDataset(Dataset):\n",
    "    def __init__(self,path,n_closeness,n_period,n_trend,tt_split,train=True):\n",
    "        self.flow_data = np.load(path)            \n",
    "        if train:\n",
    "            _, self.x_c, self.x_p, self.x_t, self.y, _, _, _, _ = get_bikenyc_data(self.flow_data,n_closeness,n_period,n_trend,tt_split)\n",
    "        else:\n",
    "            _, _, _, _, _, self.x_c, self.x_p, self.x_t, self.y = get_bikenyc_data(self.flow_data,n_closeness,n_period,n_trend,tt_split)\n",
    "        self.dataset_len = self.y.shape[0]\n",
    "        self.y = torch.tensor(self.y, device=torch.device(device)).float()\n",
    "        self.x_c = torch.tensor(self.x_c, device=torch.device(device)).float()\n",
    "        self.x_p = torch.tensor(self.x_p, device=torch.device(device)).float()\n",
    "        self.x_t = torch.tensor(self.x_t, device=torch.device(device)).float()\n",
    "        # print(self.x_c.shape, self.x_p.shape, self.x_t.shape) \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_c[idx], self.x_p[idx], self.x_t[idx], self.y[idx]\n",
    "\n",
    "bikenyc_dataset = BikeNYCDataset('./Datasets/BikeNYC/flow_data.npy',4,1,1,0.8,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2e82d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
